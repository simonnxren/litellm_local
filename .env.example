# memoria_vllm - Environment Configuration
# Copy this to .env and customize values for your deployment

# =============================================================================
# MODEL CONFIGURATION - HuggingFace model identifiers
# =============================================================================
MODEL_EMBED_NAME=Qwen/Qwen3-Embedding-0.6B
MODEL_COMPLETIONS_NAME=Qwen/Qwen3-8B-FP8
MODEL_OCR_NAME=tencent/HunyuanOCR
MODEL_WHISPER_NAME=openai/whisper-large-v3-turbo

# =============================================================================
# SERVICE PORTS
# =============================================================================
ROUTER_PORT=8200
VLLM_EMBED_PORT=8100
VLLM_COMPLETIONS_PORT=8101
VLLM_OCR_PORT=8102
VLLM_WHISPER_PORT=8103

# =============================================================================
# GPU MEMORY ALLOCATION - Fraction of total GPU memory (0.0-1.0)
# =============================================================================
# For completions+embeddings only: disable OCR/Whisper to maximize completions memory
VLLM_EMBED_GPU_MEMORY=0.11
VLLM_COMPLETIONS_GPU_MEMORY=0.57
VLLM_OCR_GPU_MEMORY=0.2
VLLM_WHISPER_GPU_MEMORY=0.11

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
# Embedding instance
VLLM_EMBED_MAX_NUM_SEQS=256
VLLM_EMBED_MAX_BATCHED_TOKENS=8192

# Completions instance
VLLM_COMPLETIONS_MAX_NUM_SEQS=128
VLLM_COMPLETIONS_MAX_BATCHED_TOKENS=65536
VLLM_COMPLETIONS_MAX_MODEL_LEN=30720
VLLM_COMPLETIONS_SCHEDULER_POLICY=fcfs

# OCR instance
VLLM_OCR_MAX_NUM_SEQS=64
VLLM_OCR_MAX_MODEL_LEN=8192

# Whisper instance
VLLM_WHISPER_MAX_NUM_SEQS=64
VLLM_WHISPER_MAX_MODEL_LEN=448
